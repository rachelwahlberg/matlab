classdef SpikeFactory
    %SPIKEFACTORY 
    % for importing spike data into matlab. First step post-Phy.
    % to create SpikeFactory object: sf = neuro.spike.SpikeFactory.instance()

    properties
        
    end
    
    methods(Access=private)
        % Guard the constructor against external invocation.  We only want
        % to allow a single instance of this class.  See description in
        % Singleton superclass.
        function obj = SpikeFactory()
            % Initialise your custom properties.
        end
    end

    methods(Static) % static means you can call it without first creating an instance of the class.
        % Concrete implementation.  See Singleton superclass.
        function obj = instance()
            persistent uniqueInstance %only one instance can be created at a time
            if isempty(uniqueInstance) % if no instance yet created
                obj = neuro.spike.SpikeFactory(); % create one
                uniqueInstance = obj;
            else
                obj = uniqueInstance;
            end
        end
    end
    
    methods
        function [sa,foldername]= getPhyOutputFolder(obj,foldername)
            logger=logging.Logger.getLogger; % creates logger object for logging messages
            import time.* % allows you to not have to type neuro.time. every time
            import neuro.spike.*
            defaultloc='/data/EphysAnalysis/cluster';
            title='Select folder for spike data';
            if ~exist('foldername','var')
                foldername = uigetdir(defaultloc,title); %uigetdir opens box to browse files
            elseif ~isfolder(foldername)
                foldername = uigetdir(defaultloc,title);
            end

            theFile=dir(fullfile(foldername,['*TimeIntervalCombined*' '.csv'])); %TIC file gives timing info for each pre-merge file
            %theFile=dir(fullfile(foldername,'..',['*TimeIntervalCombined*' '.csv']));
            if isempty(theFile)
                theFile=dir(fullfile(foldername,'..',['*TimeIntervalCombined*' '.csv']));
                logger.warning('double check your ticd file')
                if isempty(theFile)
                    theFile=dir(fullfile(foldername,'..','..',['*TimeIntervalCombined*' '.csv']));
                    logger.warning('double check your ticd file')
                    if isempty(theFile)
                        theFile=dir(fullfile(foldername,'..','..','..',['*TimeIntervalCombined*' '.csv']));
                        logger.warning('double check your ticd file')
                    else
                        logger.warning(strcat('TimeIntervalCombined is not loaded. \n\tLocation:\t',foldername,'\n'));
                    end
                end
            end
            ticd=TimeIntervalCombined(fullfile(theFile.folder, theFile.name)); % from the neuro.time folder
            
            
                prompt = {'ZT Time (SpikeFactory):'};
            dlgtitle = 'title';
            dims = [1 10];
            definput = {'12:00'};
            zt = duration(inputdlg(prompt,dlgtitle,dims,definput),'InputFormat','hh:mm');
            ticd = ticd.setZeitgeberTime(zt); % for noon start, dark to light transition

            logger.info(['time is loaded.' ticd.tostring])
           
            try
                tsvfile=fullfile(foldername,'cluster_info.tsv');
                cluster_info=SpikeFactory.getTSVCluster(tsvfile);
                logger.info('cluster_info.tsv loaded');
            catch
                logger.error(strcat('File couldn''t be found -->',fullfile(foldername,'cluster_info.tsv')))
            end
            theFile=dir(fullfile(foldername,['spike_clusters' '.npy'])); %theFile is now the spike_clusters file
            spikeclusters=readNPY(fullfile(theFile.folder, theFile.name));
            interestedFiles={'amplitudes';...
                'spike_times'};
            for ifile=1:numel(interestedFiles) % load amplitudes and spike_times
                aFile=interestedFiles{ifile};
                theFile=dir(fullfile(foldername,[aFile '.npy']));
                temps{ifile}=readNPY(fullfile(theFile.folder, theFile.name));
                logger.info([aFile '.npy is loaded'])
            end
            paramfile='/home/wahlberg/Experiments/UnitGroups.xml'; %which phy groups to include
            params=readstruct(paramfile);
            if isfield(params,'exclude')
                idx=true(size(cluster_info.group));
                idx_ex=idx;
                exclude=params.exclude;
                logger.info(strjoin([strjoin(params.exclude,', '), 'is being excluded.'],' '))
                filename1='ex_';
                for iex=1:numel(exclude)
                    theex=exclude(iex);
                    idx_ex=idx_ex & ismember(cluster_info.group,theex);
                    filename1=strcat(filename1,theex,'_');
                end
                idx=idx & ~idx_ex;
            elseif isfield(params,'include')
                    idx=false(size(cluster_info.group));
                    idx_in=idx;
                    include=params.include;
                    logger.info(strjoin([strjoin(params.include,', '), 'is being include.'],' '))
                    filename1='in_';
                    for iin=1:numel(include)
                        thein=include(iin);
                        idx_in=idx_in | ismember(cluster_info.group,thein);
                        filename1=strcat(filename1,thein,'_');
                    end
                    idx=idx | idx_in;
            else
                logger.error(strcat(paramfile,' is incorrect. It should either include or exclude noise, good, mua, unsorted.'))
            end
            cluster_info_sel=cluster_info(idx,:);
            ClusterIds=cluster_info_sel.id;
            
            idx1=ismember(spikeclusters, ClusterIds);
            for ifile=1:numel(interestedFiles)
                aFile=interestedFiles{ifile};
                temp=temps{ifile};
                data.(aFile)=temp(idx1);
            end
            data.spike_clusters=spikeclusters(idx1);
            sa=SpikeArray(data.spike_clusters,data.spike_times); %See SpikeArray for next functions
            sa=sa.setTimeIntervalCombined(ticd); %assign time info
            sa=sa.setClusterInfo(cluster_info_sel); % assign cluster info
            sastr=sa.tostring('group','ch');
            logger.info(['Phy output folder loaded. ' sastr{:}])
            ts=split(theFile.folder,filesep);
            filename=fullfile(theFile.folder,ts{numel(ts)-1});
            sa.saveCluFile(strcat(filename, '.clu.0')); % save clu and res files (see SpikeArray class)
            sa.saveResFile(strcat(filename, '.res.0'));
            logger.info(['.clu and .res files saved. ' theFile.folder])
        end
    end
    methods (Static, Access=private)
        function clustergroup=getTSVGroup(filepath)
            %% Setup the Import Options and import the data
            opts = delimitedTextImportOptions("NumVariables", 2);
            
            % Specify range and delimiter
            opts.DataLines = [2, Inf];
            opts.Delimiter = "\t";
            
            % Specify column names and types
            opts.VariableNames = ["cluster_id", "group"];
            opts.VariableTypes = ["double", "categorical"];
            
            % Specify file level properties
            opts.ExtraColumnsRule = "ignore";
            opts.EmptyLineRule = "read";
            
            % Specify variable properties
            opts = setvaropts(opts, "group", "EmptyFieldRule", "auto");
            
            % Import the data
            clustergroup = readtable(filepath, opts);
        end
        function clustergroup=getTSVCluster(filepath) %importing cluster_info.tsv
            %% Setup the Import Options and import the data
            opts = delimitedTextImportOptions("NumVariables", 9);
            
            % Specify range and delimiter
            opts.DataLines = [2, Inf];
            opts.Delimiter = "\t";
            
            % Specify column names and types - sh is the classification
            %  q in phy = class here. for the cell classification
            opts.VariableNames = {'id','amp','ch','depth','fr','group','n_spikes','purity','class','sh'};
            opts.VariableTypes = {'double','double','double','double','double', 'categorical','double','double','double','double'};
            
            % Specify file level properties
            opts.ExtraColumnsRule = "ignore";
            opts.EmptyLineRule = "read";
            
            % Specify variable properties
            opts = setvaropts(opts, "group", "EmptyFieldRule", "auto");
            
            % Import the data
            clustergroup = readtable(filepath, opts);
        end
    end
end

